Agent Communication Language (ACL)

Большинство языков общения между агентами строится на перформативах.
Наиболее распространённый стандарт - FIPA ACL.
KQML (Knowledge Query and Manipulation Language) - язык, первоначально разрабатывавшийся для обмена информацией. Его синтаксис похож на синтаксис Lisp.

Вид предложения:
(performative: 
	sender: <...>
	reciever: <...>
	...
)

Набор атрибутов не задан жёстко. 
- атрибуты sender и reciever связаны с маршрутом сообщения
- атрибуты, задающие формат сообщений: replyWith (с каким перформативом агент хотел бы получить ответ), conversationID (группировка сообщений по диалогам)
- атрибуты, связанные с интерпретацией сообщения: language (язык сообщения, определяет, как парсить содержимое сообщения), ontology (словарь: как следует интерпретировать сообщение); если вы не можете понять сообщение, то стандарт предлагает найти агента, который мог бы помочь
- content: содержание сообщения; может быть сложным, содержать внутри себя скобки; контентом может быть другое сообщение (если агент просит другого передать сообщение кому-то третьему)

Почему такой язык удобен?
1. Он заточен под использование перформативов
2. Сообщение отделено от дополнительных параметров

==================================================

После того, как мы установили коммуникацию, возникает задача социальных взаимодействий.

Насколько алгоритм взаимодействия хорош?
1. Общая полезность
Функция, которая измеряет, насколько ситуация хороша в целом и насколько она хороша для каждого отдельного агента. Цель - найти точку максимума общей полезности. Как правило, точка максимума либо не существует, либо не единственна, либо агенты не могут туда попасть.
2. Эффективность решения по Парето
Ситуация эффективна по Парето, если нельзя сделать кому-то лучше, не сделав при этом кому-то хуже.
Пример: <картинка 1>
3. Стабильность
Важно обеспечить, чтобы агенты следовали протоколу; но у агента есть свои цели и автономия, и если ему будет выгодно отойти от плана, он, скорее всего, от него отойдёт. Нужен план, от которого бы агенты не хотели отклониться.
Способы добиться этого:
- доминантные стратегии: агент получает максимальную выгоду независимо от поведения других агентов; не следовать ей значит потерять
- равновесие Нэша: все ведут себя так, как оптимально в данной ситуации с учётом действия других

Пример: дилемма заключённого.
У каждого преступника есть выбор: он может молчать и не сознаваться, и тогда у полиции нет доказательств. А может сдать подельника, и тогда предателя отпустят, а остальных посадят надолго.
Матрица принятия решения:
	молчать	говорить
молчать  (6, 6)  (0, 8)
говорить (8, 0)	 (1, 1)
Максимум общей полезности достигается в ситуации, когда все молчат. Точки, оптимальные по Парето - три точки (кроме говорить-говорить). А равновесие по Нэшу достигается как раз в ней (и в жизни они, скорее всего, попадут именно в неё), потому что из точки (6, 6) агенты перейдут в (0, 8) и в (8, 0), а оттуда уже в (1, 1). 
В жизни есть много хороших решений, которые мы могли бы реализовать, но не можем, потому что не доверяем второй стороне, и поэтому приходится действовать по наименее эффективной стратегии.
Этот эксперимент разрушается, когда появляется взаимодействие (общение) между заключёнными или вероятностная характеристика.
Равновесие по Нэшу не является защищённым с точки зрения коалиции. В подмножестве агентов оптимальная стратегия другая, нежеди для одного агента. Коалиция из двух заключённых выйдет из равновесия по Нэшу.

4. Сложность вычисления
5. Сложность коммуникации
4 и 5 идут в некоторй противофазе (т.е. увеличивая сложность коммуникаций, можно уменьшить сложность вычислений, и наоборот)
6. Централизованность
Если в алгоритме есть центральное звено, но система становится менее живучей (если есть такое звено, выход его из строя выводит всю систему из строя).
7. Открытость
Алгоритм допускает появление новых участников в процессе. 

==================================================

Как агенты могут друг другу помочь?

При проектировании алгоритма есть две опции:
1. Task sharing: агенты делят задачи между собой
Сначала агенты координируются и решают, что делать.
2. Results sharing: агенты предоставляют полученные результаты коллегам
Агент решает задачу, которая ему нужна, получает результат и может предложить его другим агентам (т.е. сначала агент делает, а потом предоставляет результат другим)

Некоторые методы не укладываются в эти схемы (например, методы, связанные с оптимизацией), но большинство укладывается.

==================================================

Наиболее распространённые способы взаимодействия:
1. Выборы
Агентам нужно принять какое-то совместное решение. Сначала они обсуждают, потом деляют выбор, и после этого он становится обязательным предписанием.
Проблемы нерелевантных альтернатив: может выбраться не та альтернатива, которая максимизирует полезность, потому что появился конкурент. Выборы - хороший вариант при единой политике.
2. Аукционы
Отличие от выборов: принятое решение является обязательным не для всех, а лишь для нескольких. Аукционных протоколов довольно много. С вычислительной точки зрения аукционы бывают простыми благодаря простым доминантным стратегиям.
3. Сети контрактов
Исторически - один из самых первых алгоритмов. Есть задачи, которые нужно сделать; открываем тендер, получаем предложения, выбираем самое выгодное. Задачи можно разбивать на подзадачи и по каждой устраивать тендер. 
Задачи часто выгодно передать другому, а не решать самому, потому что есть некоторая синергия задач (например, если мы везём груз из А в Б, мы можем с собой взять ещё, для нас это ничего не стоит).
4. Рынок
Пытаемся свести задачи к модели цен/производителей/потребителей. Агенты симулируют поведение людей: потребители пытаются максимизировать полезность при материальных ограничениях, производители - максимизировать выгоду. Задача: "выровнять" ситуацию. 
Для реализации рынок - один из самых сложных алгоритмов (из-за динамики; рынок не всегда сходится туда, куда мы ожидали; иногда он вообще может не сойтись).
5. Согласование контрактов
Мы рассчитываем, что агентов немного, но сами агенты достаточно сложно рассуждают. Суть метода: переговорный процесс. Один агент предлагает вариант, второй соглашается или нет, тогда предлагает свой вариант, и т.д.
В таком алгоритме учитывается много критериев. Для того, чтобы агенты договорились, важно, чтобы у них были лимиты (они не должны уйти в бесконечный спор, а всё-таки решить что-то). 
6. Объединение в коалиции
Направлен на уменьшение коммуникационной сложности. Если коммуникация идёт "каждый с каждым", то связи растут квадратично. Чтобы этого избежать, объединяем агентов в коалиции, и дальше коалиция представляет себя как единый агент. Внутри коалиции агенты могут взаимодействовать. Вычленение оптимальной коалиции - задача, для которой существует несколько алгоритмов.

Это семейство алгоритмов основано на копировании "человеческих подходов".

==================================================

Алгоритмы, "копированные с природы".
1. ACO (Colony Optimization)
Ищем пути в графе; решаем задачу, запустив некоторое количество "муравьёв". Муравьи выделяют феромоны, помечающие дуги, по которым он проходил; другие муравьи ориентируются на свои мотивации и на уровень феромонов. Через некоторое количество итераций дуги, лежащие на кратчайшем пути, становятся самыми "феромонистыми".
Многие задачи сводятся к графовым (например, планирования ресурсов).
2. Bees
Пчёлами оптимизируем функции.
В рое есть разведчик, он вылетает и разведывает местность. Возвращаясь, исполняет "танец", сообщающий информацию о местности. Пчёлы, которые заинтересованы в такой местности, улетают с разведчиком, исследуют местность, возвращаются и сообщают информацию и т.д.
Для функций: 
- например, у нас есть кусочно-непрерывная функция, хотим найти минимум. Градиентным спуском решить не можем, а посылкой разведчиков можем
- невыпуклая функция: мы можем застрять в каком-нибудь локальном минимуме, градиентный спуск не захочет из него выходить; а пчёлы могут случайно зондировать и найти результат лучше)
3. Fireflies
Светлячки - гермафродиты, и единственный критерий для выбора партнёра у них - яркость света. Яркость убывает с расстоянием. Каждый светлячок выбирает направление, связанное с тем, где находится наиболее яркий (для него) светлячок.
Алгоритм помогает в задачах кластеризации, поиска коалиций.
4. PSO
Есть частицы, у них есть масса, они притягивают другие частицы. Отличие от светлячков: выбираем одного, летим к нему, а здесь направление движения определяется всеми частицами.
5. Genetic (оно не про оптимизацию, а про симуляцию)
Идея: есть начальная популяция, мы оцениванием, насколько объекты хороши (fitness); выбираем лучших и переводим на следующий этап, комбинируем, генерируем следующую популяцию и т.д.